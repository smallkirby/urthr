const Self = @This();

pub const BuddyAllocator = Self;
pub const Error = PageAllocator.Error;

/// Spin lock for this allocator.
lock: SpinLock,
/// Arena.
arena: Arena,

/// Vtable for PageAllocator interface.
const vtable = PageAllocator.Vtable{
    .allocPages = allocPages,
    .freePages = freePages,
    .virt2phys = virt2physInterface,
    .phys2virt = phys2virtInterface,
};

/// Exponent of power of 2 representing the number of contiguous physical pages.
const SizeOrder = u8;
/// Physical address type.
const Phys = usize;
/// Virtual address type.
const Virt = usize;

/// Page size in bytes.
const page_size = 4 * units.kib;
//// Page size shift.
const page_shift = 12;
/// Page size mask.
const page_mask = page_size - 1;

/// Initialize buddy allocator.
///
/// - `avail`     : Memory region that the allocator can use.
/// - `reserveds` : List of reserved regions that the allocator must not use.
///
/// `reserveds` may be not sorted, but must not overlap each other.
///
/// All arguments are in physical addresses.
pub fn init(self: *Self, avails: []const Range, reserveds: []Range, log_fn: ?urd.LogFn) void {
    self.* = .{
        .lock = SpinLock{},
        .arena = Arena.new(),
    };

    // Sort `reserveds` by the starting address.
    {
        const sort_fn = struct {
            fn lt(_: void, lhs: Range, rhs: Range) bool {
                return lhs.start < rhs.start;
            }
        }.lt;
        std.mem.sort(Range, reserveds, {}, sort_fn);
    }

    // Feed the available regions to the arena,
    for (avails) |avail| {
        rtt.expectEqual(0, avail.start & page_mask);
        rtt.expectEqual(0, avail.end & page_mask);

        var cur = avail.start;
        const end = avail.start + avail.size();

        for (reserveds) |r| {
            const reserved_start = r.start;
            const reserved_end = reserved_start + util.roundup(r.size(), page_size);
            rtt.expectEqual(0, reserved_start & page_mask);
            rtt.expectEqual(0, reserved_end & page_mask);

            if (reserved_end <= cur) continue;

            const cur_size = reserved_start - cur;
            if (cur_size != 0) {
                self.arena.addRegion(cur, cur + cur_size);
            }
            cur = reserved_end;
        }

        if (cur != end) {
            self.arena.addRegion(cur, end);
        }
    }

    // Debug print stats.
    if (log_fn) |f| {
        self.debugPrintStatistics(f);
    }

    // Runtime test.
    rttTestBuddyAllocator(self);
}

/// Get the PageAllocator interface.
pub fn interface(self: *Self) PageAllocator {
    return .{
        .ptr = self,
        .vtable = &vtable,
    };
}

/// Manages free lists of each order for single memory zone.
///
/// The list must be sorted in ascending order of physical addresses.
/// Each page is ensured to be aligned to the order.
const FreeList = struct {
    /// Doubly linked list of free pages.
    link: FreePageLink,
    /// Total number of blocks for the free list.
    ///
    /// This contains both used and free blocks.
    num_total: usize,

    /// Doubly linked list of free pages.
    pub const FreePageLink = DoublyLinkedList;
    /// Free page.
    ///
    /// This struct is placed at the beginning of the free pages.
    pub const FreePage = DoublyLinkedList.Node;

    /// Create a new empty free list.
    pub fn new() FreeList {
        return FreeList{
            .link = FreePageLink{},
            .num_total = 0,
        };
    }

    /// Add a memory region to this free list.
    pub fn addRegion(self: *FreeList, phys: Phys) *FreePage {
        const new_page: *FreePage = @ptrFromInt(phys2virt(phys));
        self.insertSorted(new_page);
        self.num_total += 1;
        return new_page;
    }

    /// Allocate a block of pages from the free list.
    pub fn allocBlock(self: *FreeList) Error!*FreePage {
        return self.link.popFirst() orelse Error.OutOfMemory;
    }

    /// Detach the given block from the freelist.
    ///
    /// Detached pages are no longer managed by the free list.
    /// Caller MUST ensure that the block is in the list.
    pub fn detachBlock(self: *FreeList, block: *FreePage) void {
        self.link.remove(block);
        self.num_total -= 1;
    }

    /// Detach the first block in the freelist.
    ///
    /// Detached pages are no longer managed by the free list.
    pub fn detachFirstBlock(self: *FreeList) Error!*FreePage {
        const page = self.link.first orelse return Error.OutOfMemory;
        self.detachBlock(page);
        return page;
    }

    /// Add a block of pages to the free list.
    pub fn freeBlock(self: *FreeList, block: []u8) *FreePage {
        // BUG: Zig v0.14.0 : https://github.com/ziglang/zig/issues/22885
        // const page: *FreePage = @alignCast(@ptrCast(block));
        const work_around_ptr: u64 = @intFromPtr(block.ptr);
        const page: *FreePage = @ptrFromInt(work_around_ptr);

        self.insertSorted(page);
        return page;
    }

    /// Insert the block to the freelist keeping list sorted.
    ///
    /// Note that this function does not increment the counter.
    ///
    /// TODO: Use binary search.
    fn insertSorted(self: *FreeList, new_page: *FreePage) void {
        // Starting from the last block, find the first block whose address is smaller than the new block.
        var cur: ?*FreePage = self.link.last;
        while (cur) |page| : (cur = page.prev) {
            if (@intFromPtr(page) < @intFromPtr(new_page)) break;
        }
        if (cur) |c| {
            self.link.insertAfter(c, new_page);
        } else {
            self.link.prepend(new_page);
        }
    }

    /// Check if the list does not have any free pages.
    pub fn isEmpty(self: *FreeList) bool {
        return self.numFree() == 0;
    }

    /// Get the number of blocks in the freelist.
    ///
    /// Blocks in use are included.
    pub inline fn numTotal(self: FreeList) usize {
        return self.num_total;
    }

    /// Get the number of blocks in the freelist.
    pub inline fn numFree(self: FreeList) usize {
        return self.link.len();
    }

    /// Get the number of blocks in use.
    pub inline fn numInUse(self: FreeList) usize {
        return self.num_total - self.numFree();
    }
};

/// Manages free lists of each order for single memory zone.
const Arena = struct {
    /// Available number of page orders.
    const avail_orders: usize = 10;
    /// If the number of free blocks is larger than this threshold, try merge adjacent blocks.
    const merge_threshold: usize = 10;

    /// Free list for each order.
    lists: [avail_orders]FreeList,

    /// Create a new arena.
    pub fn new() Arena {
        return Arena{
            .lists = [_]FreeList{FreeList.new()} ** avail_orders,
        };
    }

    /// Add a memory region to the free list.
    pub fn addRegion(self: *Arena, start: Phys, end: Phys) void {
        rtt.expect(start < end);

        var cur_start = start;
        while (true) {
            const size = end - cur_start;
            const orig_order, var remaining = orderFloor(size / page_size);

            // Find the order that matches the alignment.
            var order = orig_order;
            while (order != 0) {
                const mask = getOrderMask(order);
                if (cur_start & mask == 0) break;
                order -= 1;
            }
            remaining += orderToInt(orig_order) - orderToInt(order);

            // Add the region to the free list.
            const new_page = self.getList(order).addRegion(cur_start);
            self.maybeMergeRecursive(new_page, order);

            cur_start += orderToInt(order) * page_size;
            if (remaining == 0) break;
        }
    }

    /// Allocate the given number of pages.
    pub fn allocPages(self: *Arena, num_pages: usize) Error![]align(page_size) u8 {
        const order = roundUpToOrder(num_pages);
        const free_list = self.getList(order);

        const block = free_list.allocBlock() catch retry: {
            // Split the free list and retry.
            self.splitRecursive(order + 1);
            break :retry try free_list.allocBlock();
        };

        const ptr: [*]align(page_size) u8 = @ptrCast(@alignCast(block));
        return ptr[0 .. num_pages * page_size];
    }

    /// Free the given pages to the appropriate list.
    pub fn freePages(self: *Arena, pages: []u8) void {
        const order = roundUpToOrder(pages.len / page_size);
        rtt.expectEqual(0, @intFromPtr(pages.ptr) & getOrderMask(order));

        const new_page = self.getList(order).freeBlock(pages);
        self.maybeMergeRecursive(new_page, order);
    }

    /// Split pages in the `order`-th freelist the `order - 1`-th freelist.
    ///
    /// If the `order`-th freelist is empty, this function is called recursively for larger list.
    fn splitRecursive(self: *Arena, order: SizeOrder) void {
        rtt.expect(order != 0);

        const lower_order = order - 1;
        const free_list = self.getList(order);

        // Ensure that the freelist is not empty.
        if (free_list.isEmpty()) {
            self.splitRecursive(order + 1);
            rtt.expectEqual(false, free_list.isEmpty());
        }

        const block = free_list.detachFirstBlock() catch {
            @panic("BuddyAllocator: failed to split the free list.");
        };

        const block_size = orderToInt(lower_order) * page_size;
        const num_blocks = (orderToInt(order) * page_size) / block_size;
        rtt.expectEqual(2, num_blocks);
        for (0..2) |i| {
            // We dont't merge here.
            _ = self.getList(lower_order).addRegion(
                virt2phys(@intFromPtr(block)) + i * block_size,
            );
        }
    }

    /// Try ty merge blocks adjacent to the given block recursively.
    fn maybeMergeRecursive(self: *Arena, page: *FreeList.FreePage, order: SizeOrder) void {
        // If the order is the largest, we can't merge anymore.
        if (order == avail_orders - 1) return;
        // If the number of free blocks is small, we don't merge.
        if (self.getList(order).numFree() < merge_threshold) return;

        const higher_order = order + 1;
        const higher_mask = getOrderMask(higher_order);
        const adjacent_distance = orderToInt(order) * page_size;

        // Find the adjacent block.
        const t1, const t2 = if (@intFromPtr(page) & higher_mask == 0) blk: {
            // The given block is the lower one.
            break :blk if (page.next != null and @intFromPtr(page.next.?) == @intFromPtr(page) + adjacent_distance) .{
                page,
                page.next.?,
            } else .{
                null,
                null,
            };
        } else blk: {
            // The given block is the higher one.
            break :blk if (page.prev != null and @intFromPtr(page.prev.?) == @intFromPtr(page) - adjacent_distance) .{
                page.prev.?,
                page,
            } else .{
                null,
                null,
            };
        };

        // If we find the adjacent block, merge them recursively.
        if (t1 != null and t2 != null) {
            const lower_list = self.getList(order);
            const higher_list = self.getList(higher_order);

            lower_list.detachBlock(t1.?);
            lower_list.detachBlock(t2.?);

            const new_page = higher_list.addRegion(virt2phys(@intFromPtr(t1.?)));
            self.maybeMergeRecursive(new_page, higher_order);
        }
    }

    /// Get the free list for the given order.
    inline fn getList(self: *Arena, order: SizeOrder) *FreeList {
        return &self.lists[order];
    }

    /// Get the address mask for the order.
    fn getOrderMask(order: SizeOrder) u64 {
        return ((@as(usize, 1) << page_shift) << @as(u6, @intCast(order))) - 1;
    }

    /// Convert the number of pages to the order.
    ///
    /// If the num is not a power of 2, the order is rounded down and the remaining size is returned.
    /// If the order exceeds the available orders, the order is clamped to the max.
    /// Returns the pair of the order and the remaining number of pages.
    fn orderFloor(num_pages: usize) struct { SizeOrder, usize } {
        rtt.expect(num_pages != 0);

        var order = std.math.log2_int(usize, num_pages);
        if (order >= avail_orders) {
            order = avail_orders - 1;
        }
        const remaining = num_pages - (@as(usize, 1) << order);

        return .{ @intCast(order), remaining };
    }

    /// Convert the order to integer.
    inline fn orderToInt(order: SizeOrder) usize {
        return @as(usize, 1) << @intCast(order);
    }

    /// Align the number of pages to the order.
    inline fn roundUpToOrder(num_pages: usize) SizeOrder {
        rtt.expect(num_pages != 0);
        return std.math.log2_int_ceil(usize, num_pages);
    }
};

/// Convert the given virtual address to physical address.
fn virt2phys(vaddr: usize) usize {
    return vaddr - vmap.linear.start;
}

/// Convert the given physical address to virtual address.
fn phys2virt(paddr: usize) usize {
    return paddr + vmap.linear.start;
}

// =============================================================
// Interface
// =============================================================

fn allocPages(ctx: *anyopaque, num_pages: usize) Error![]align(page_size) u8 {
    const self: *Self = @ptrCast(@alignCast(ctx));
    self.lock.lock();
    defer self.lock.unlock();

    const vpages = try self.arena.allocPages(num_pages);
    const vptr: [*]u8 = @ptrFromInt(virt2phys(@intFromPtr(vpages.ptr)));
    return @alignCast(vptr[0..vpages.len]);
}

fn freePages(ctx: *anyopaque, pages: []u8) void {
    const self: *Self = @ptrCast(@alignCast(ctx));
    self.lock.lock();
    defer self.lock.unlock();

    const vptr: [*]u8 = @ptrFromInt(phys2virt(@intFromPtr(pages.ptr)));
    const vpages: []align(page_size) u8 = @alignCast(vptr[0..pages.len]);

    self.arena.freePages(vpages);
}

fn virt2physInterface(_: *const anyopaque, vaddr: usize) usize {
    return virt2phys(vaddr);
}

fn phys2virtInterface(_: *const anyopaque, paddr: usize) usize {
    return phys2virt(paddr);
}

// =============================================================
// Debug
// =============================================================

// Debug print the statistics of managed regions.
fn debugPrintStatistics(self: *Self, log_fn: urd.LogFn) void {
    log_fn("Statistics of Buddy Allocator's initial state:", .{});
    const arena = &self.arena;
    log_fn(
        "{s: <7}                   Used / Total",
        .{"Normal"},
    );

    var total_pages: usize = 0;
    var total_inuse_pages: usize = 0;
    for (arena.lists, 0..) |list, order| {
        const page_unit = Arena.orderToInt(@intCast(order));
        const pages = page_unit * list.numTotal();
        const inuse_pages = page_unit * list.numInUse();
        total_pages += pages;
        total_inuse_pages += inuse_pages;
        log_fn(
            "   {d: >2}: {d: >7} ({d: >7} pages) / {d: >7} ({d: >7} pages)",
            .{ order, list.numInUse(), inuse_pages, list.numTotal(), pages },
        );
    }

    log_fn(
        "    >             {d:>8} MiB / {d: >8} MiB",
        .{ total_inuse_pages * page_size / units.mib, total_pages * page_size / units.mib },
    );
}

// =============================================================
// Tests
// =============================================================

const testing = std.testing;
const rtt = urd.rtt;

const TestingAllocatedList = DoublyLinkedList;
const TestingAllocatedNode = TestingAllocatedList.Node;

/// Runtime test for BuddyAllocator.
fn rttTestBuddyAllocator(buddy_allocator: *Self) void {
    if (!urd.enable_rtt) return;

    const allocator = buddy_allocator.interface();
    const arena = &buddy_allocator.arena;

    // Allocate 3 pages (from 2-th freelist) and check the alignment.
    {
        const page = allocator.allocPagesV(3) catch {
            @panic("Unexpected failure in rttTestBuddyAllocator()");
        };
        // Must be aligned to 16 KiB.
        rtt.expectEqual(0, @intFromPtr(page.ptr) & 0x3_FFF);
        allocator.freePagesV(page);
    }

    // Record the initial state.
    var allocated_pages_order0 = TestingAllocatedList{};
    const num_free_order0 = arena.lists[0].numFree();
    const num_inuse_order0 = arena.lists[0].numInUse();
    const num_free_order1 = arena.lists[1].numFree();
    const num_inuse_order1 = arena.lists[1].numInUse();
    const num_free_order2 = arena.lists[2].numFree();
    const num_inuse_order2 = arena.lists[2].numInUse();

    // Consume all pages from 0-th freelist.
    {
        var prev: [*]allowzero u8 = @ptrFromInt(0);
        for (0..num_free_order0) |_| {
            const page = rttAllocatePage(&allocated_pages_order0, allocator);
            // Blocks in the freelist must be sorted.
            rtt.expect(@intFromPtr(prev) < @intFromPtr(page.ptr));
            prev = page.ptr;
        }
        rtt.expectEqual(0, arena.lists[0].link.len());
        rtt.expectEqual(null, arena.lists[0].link.first);
        rtt.expectEqual(null, arena.lists[0].link.last);
    }

    // Split pages in the 1-st freelist to the 0-th.
    rtt.expect(num_free_order1 != 0);
    {
        const page1 = rttAllocatePage(&allocated_pages_order0, allocator);
        const page2 = rttAllocatePage(&allocated_pages_order0, allocator);

        // Two pages must be contiguous because they are split from the same block.
        rtt.expectEqual(@intFromPtr(page1.ptr) + page_size, @intFromPtr(page2.ptr));
    }

    // Free all pages and see if they are merged.
    // The state of the arena may change due to split & merge logic.
    {
        // Free pages in the order of allocation.
        var cur = allocated_pages_order0.first;
        while (cur) |c| {
            const page: [*]u8 = @ptrCast(c);
            cur = c.next; // We have to store the value here before the page is freed.
            allocator.freePagesV(page[0..page_size]);
        }

        rtt.expectEqual(
            num_inuse_order0 * 1 + num_inuse_order1 * 2 + num_inuse_order2 * 4,
            arena.lists[0].numInUse() * 1 + arena.lists[1].numInUse() * 2 + arena.lists[2].numInUse() * 4,
        );
        rtt.expectEqual(
            num_free_order0 * 1 + num_free_order1 * 2 + num_free_order2 * 4,
            arena.lists[0].numFree() * 1 + arena.lists[1].numFree() * 2 + arena.lists[2].numFree() * 4,
        );
    }

    // Check if they're still sorted.
    {
        var prev: *allowzero FreeList.FreePage = @ptrFromInt(0);
        var cur = arena.lists[0].link.first;
        while (cur) |c| : (cur = cur.?.next) {
            rtt.expect(@intFromPtr(prev) < @intFromPtr(c));
            prev = c;
        }
    }
}

fn rttAllocatePage(list: *TestingAllocatedList, allocator: PageAllocator) []align(page_size) u8 {
    const page = allocator.allocPagesV(1) catch {
        @panic("Unexpected failure in rttAllocatePage()");
    };
    const new_page: *TestingAllocatedNode = @ptrCast(page.ptr);
    list.append(new_page);
    return page;
}

test "Arena.getOrderMask" {
    try testing.expectEqual(0xFFF, Arena.getOrderMask(0));
    try testing.expectEqual(0x1FFF, Arena.getOrderMask(1));
    try testing.expectEqual(0x3FFF, Arena.getOrderMask(2));
    try testing.expectEqual(0x7FFF, Arena.getOrderMask(3));
    try testing.expectEqual(0xFFFF, Arena.getOrderMask(4));
    try testing.expectEqual(0x1FFFF, Arena.getOrderMask(5));
    try testing.expectEqual(0x3FFFF, Arena.getOrderMask(6));
    try testing.expectEqual(0x7FFFF, Arena.getOrderMask(7));
    try testing.expectEqual(0xFFFFF, Arena.getOrderMask(8));
    try testing.expectEqual(0x1FFFFF, Arena.getOrderMask(9));
    try testing.expectEqual(0x3FFFFF, Arena.getOrderMask(10));
}

test "Arena.orderFloor" {
    try testing.expectEqual(.{ 0, 0 }, Arena.orderFloor(1));
    try testing.expectEqual(.{ 1, 0 }, Arena.orderFloor(2));
    try testing.expectEqual(.{ 1, 1 }, Arena.orderFloor(3));
    try testing.expectEqual(.{ 2, 0 }, Arena.orderFloor(4));
}

test "Arena.orderToInt" {
    try testing.expectEqual(1, Arena.orderToInt(0));
    try testing.expectEqual(2, Arena.orderToInt(1));
    try testing.expectEqual(4, Arena.orderToInt(2));
    try testing.expectEqual(8, Arena.orderToInt(3));
}

test "Arena.roundUpToOrder" {
    try testing.expectEqual(0, Arena.roundUpToOrder(1));
    try testing.expectEqual(1, Arena.roundUpToOrder(2));
    try testing.expectEqual(2, Arena.roundUpToOrder(3));
    try testing.expectEqual(2, Arena.roundUpToOrder(4));
    try testing.expectEqual(3, Arena.roundUpToOrder(5));
    try testing.expectEqual(3, Arena.roundUpToOrder(8));
    try testing.expectEqual(4, Arena.roundUpToOrder(9));
    try testing.expectEqual(4, Arena.roundUpToOrder(16));
}

// =============================================================
// Imports
// =============================================================

const std = @import("std");
const DoublyLinkedList = std.DoublyLinkedList;
const common = @import("common");
const units = common.units;
const util = common.util;
const PageAllocator = common.PageAllocator;
const Range = common.Range;
const urd = @import("urthr");
const SpinLock = urd.SpinLock;
const vmap = @import("vmemmap.zig");
